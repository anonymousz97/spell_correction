{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c349f2e2-141d-4a63-b196-ca659eefbc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torch import Tensor\n",
    "import traceback\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "import string\n",
    "import ast\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 512):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class SpellCorrectionModel(nn.Module):\n",
    "    def __init__(self, word_vocab_size, char_vocab_size, char_embedding_dim=256, word_embedding_dim=768, word_n_head=8, char_n_head=4, word_ffw=786, char_ffw=256):\n",
    "        super(SpellCorrectionModel, self).__init__()\n",
    "        self.word_embedding_dim = word_embedding_dim\n",
    "        self.word_embedding = nn.Embedding(word_vocab_size, word_embedding_dim, padding_idx=0)\n",
    "        self.char_embedding = nn.Embedding(char_vocab_size, char_embedding_dim, padding_idx=0)\n",
    "\n",
    "        self.pos_encoder = PositionalEncoding(word_embedding_dim+char_embedding_dim, dropout=0.1)\n",
    "        self.norm_w = nn.LayerNorm(word_embedding_dim+char_embedding_dim)\n",
    "        self.norm_c = nn.LayerNorm(char_embedding_dim)\n",
    "        word_transformer = nn.TransformerEncoderLayer(d_model=(word_embedding_dim+char_embedding_dim), nhead=word_n_head, dim_feedforward=(word_ffw+char_ffw), dropout=0.1, activation='gelu', batch_first=True)\n",
    "        self.word_transformer_encoder = nn.TransformerEncoder(word_transformer, num_layers=12, norm=self.norm_w)\n",
    "        char_transformer = nn.TransformerEncoderLayer(d_model=char_embedding_dim, nhead=char_n_head, dim_feedforward=char_ffw, dropout=0.1, activation='gelu', batch_first=True)\n",
    "        self.char_transformer_encoder = nn.TransformerEncoder(char_transformer, num_layers=4, norm=self.norm_c)\n",
    "        # self.linear_layer = nn.Linear(char_embedding_dim, 768)\n",
    "\n",
    "        self.correction = nn.Linear(word_embedding_dim+char_embedding_dim, word_vocab_size)\n",
    "        # self.softmax = nn.Softmax(dim=-1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.is_correct = nn.Linear(word_embedding_dim+char_embedding_dim, 1)\n",
    "\n",
    "    def forward(self, word_text, char_text):\n",
    "        w = torch.tensor(word_text).to(device)\n",
    "        c = torch.tensor(char_text).to(device)\n",
    "\n",
    "        # print(\"Input : \",w.shape,c.shape)\n",
    "\n",
    "        # assign mask for word and char\n",
    "        padding_mask_w = (w != 0).float()\n",
    "\n",
    "        # padding_mask_c = (torch.sum(c,dim=-1,keepdims=False) != 0).unsqueeze(2).float()\n",
    "        # padding_mask_c = (c != 0).unsqueeze(3).float()\n",
    "\n",
    "        # print(\"mask w : \",padding_mask_w.shape)\n",
    "        # print(\"mask c : \",padding_mask_c.shape)\n",
    "\n",
    "        word_embedded_text = self.word_embedding(w)\n",
    "        char_embedded_text = self.char_embedding(c)\n",
    "\n",
    "        char_embedded_text = torch.mean(char_embedded_text, dim=2, keepdims=False)\n",
    "        char_embedded_text = self.char_transformer_encoder(char_embedded_text, src_key_padding_mask=padding_mask_w)\n",
    "        linear_input = torch.cat((word_embedded_text, char_embedded_text), dim=2)\n",
    "        src = self.pos_encoder(linear_input)\n",
    "        output = self.word_transformer_encoder(src, src_key_padding_mask=padding_mask_w)\n",
    "        output_spell = self.sigmoid(self.is_correct(output))\n",
    "        output_correction = self.correction(output)\n",
    "        # print(output_spell,output_correction)\n",
    "        #print(\"Output position fix : \",output_correction.shape)\n",
    "        \n",
    "        return output_correction.cpu(), output_spell.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69c83828-504b-4eb6-baab-3b49285d222b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('merge_word_vocab_13126.txt','r') as f:\n",
    "    word_tokenizer = f.read().split('\\n')\n",
    "word_tokenizer.insert(0,\"<unk>\")\n",
    "word_tokenizer.insert(0,\"<pad>\")\n",
    "word_tokenizer.insert(0,\"<end>\")\n",
    "word_tokenizer.insert(0,\"<start>\")\n",
    "\n",
    "map_word = {j:i for i,j in enumerate(word_tokenizer)}\n",
    "# map_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "336c68db-8346-428a-83a7-12baca99660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('char_vocab.txt','r') as f:\n",
    "    char_tokenizer = f.read().split('\\n')\n",
    "char_tokenizer.insert(0,\"<unk>\")\n",
    "char_tokenizer.insert(0,\"<pad>\")\n",
    "char_tokenizer.insert(0,\"<end>\")\n",
    "char_tokenizer.insert(0,\"<start>\")\n",
    "\n",
    "map_char = {j:i for i,j in enumerate(char_tokenizer)}\n",
    "# map_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e09ca51b-8e6d-415a-bd50-7b101e7ee688",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = [\"Hôm nay trời thật đẹp\",\"Chủ nhật này đi chơi không ?\"]\n",
    "\n",
    "def mapping_batch(sample):\n",
    "    try:\n",
    "        max_word_length = max([len(x.split(' ')) for x in sample])\n",
    "        max_char_length = max([max([len(word) for word in sentence.split(' ')]) for sentence in sample])\n",
    "    except:\n",
    "        return \"\", \"\", 0\n",
    "    # #print(max_word_length, max_char_length)\n",
    "    res = []\n",
    "    res_char = []\n",
    "    for i in sample:\n",
    "        out = []\n",
    "        out_char = []\n",
    "        for j in i.split(' '):\n",
    "            out.append(map_word[j] if j in map_word.keys() else map_word['<unk>'])\n",
    "            r = []\n",
    "            for g in j:\n",
    "                r.append(map_char[g] if g in map_char.keys() else map_char['<unk>'])\n",
    "            while len(r) < max_char_length:\n",
    "                r.append(2)\n",
    "            out_char.append(r)\n",
    "        while len(out) < max_word_length:\n",
    "            out.append(2)\n",
    "            out_char.append([2] * max_char_length)\n",
    "            \n",
    "        res.append(out)\n",
    "        res_char.append(out_char)\n",
    "    return res, res_char , max_word_length\n",
    "\n",
    "# mapping_batch(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1213df0-47b5-4925-98da-284e5b20e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f2d2309-893a-4c0b-9413-69dad308edd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate your model and optimizer\n",
    "loaded_model = SpellCorrectionModel(13130,214).to(device)\n",
    "loaded_model.eval()\n",
    "loaded_optimizer = optim.Adam(loaded_model.parameters(), lr=0.001)\n",
    "\n",
    "# Load the saved model and optimizer state\n",
    "checkpoint = torch.load('latest.pth')\n",
    "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "loaded_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# If you need to continue training, set the model to training mode\n",
    "# loaded_model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6aa1e80c-5a16-4af0-a80c-64147b0d9b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Trong dài hạn , siegel cho biết : Nhữmg mối quan hệ này không thực sự ạ ra trái nnngọt .',\n",
       " 'Hiện tại , harvard đanng nỗ lực sắp p lại cơ cấu tổ chức và danh mục đầu tư của quỹ hiến tặng.']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = df_test.generate.values.tolist()[0:2]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ddae3c32-9c4d-4f6f-85a9-c56f0ac93df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, c, max_length = mapping_batch(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6ddb56a3-6662-4667-a004-d8bc1c3c20a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 2. Expected size 23 but got size 0 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 2\u001b[0m     output_correction, output_spell \u001b[38;5;241m=\u001b[39m \u001b[43mloaded_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[11], line 77\u001b[0m, in \u001b[0;36mSpellCorrectionModel.forward\u001b[0;34m(self, word_text, char_text)\u001b[0m\n\u001b[1;32m     75\u001b[0m char_embedded_text \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(char_embedded_text, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     76\u001b[0m char_embedded_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchar_transformer_encoder(char_embedded_text, src_key_padding_mask\u001b[38;5;241m=\u001b[39mpadding_mask_w)\n\u001b[0;32m---> 77\u001b[0m linear_input \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword_embedded_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchar_embedded_text\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoder(linear_input)\n\u001b[1;32m     79\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword_transformer_encoder(src, src_key_padding_mask\u001b[38;5;241m=\u001b[39mpadding_mask_w)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 2. Expected size 23 but got size 0 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output_correction, output_spell = loaded_model(w, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a609d926-6a1d-48bd-8d72-8f6310d65b8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0716],\n",
       "         [0.0745],\n",
       "         [0.0771],\n",
       "         [0.0751],\n",
       "         [0.0834],\n",
       "         [0.0896],\n",
       "         [0.0729],\n",
       "         [0.0781],\n",
       "         [0.0740],\n",
       "         [0.0794],\n",
       "         [0.0701],\n",
       "         [0.0824],\n",
       "         [0.0752],\n",
       "         [0.0726],\n",
       "         [0.0722],\n",
       "         [0.0736],\n",
       "         [0.0794],\n",
       "         [0.0786],\n",
       "         [0.0803],\n",
       "         [0.0726],\n",
       "         [0.0721]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_spell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "123afcb6-f5bc-4927-8125-057abc773e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trong dài hạn , Siegel cho biết : Những mối qu...</td>\n",
       "      <td>Trong dài hạn , siegel cho biết : Nhữmg mối qu...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiện tại , Harvard đang nỗ lực sắp xếp lại cơ ...</td>\n",
       "      <td>Hiện tại , harvard đanng nỗ lực sắp p lại cơ c...</td>\n",
       "      <td>[0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Và việc rút vốn khỏi công ty của Mindich là mộ...</td>\n",
       "      <td>àV việc Rút vốn khỏi công ty của mindich là mộ...</td>\n",
       "      <td>[1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Giống như nhiều đối thủ khác , Harvard đã từ l...</td>\n",
       "      <td>Giống như nhiều đđđối thủ khác , harvard ã từ ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuy nhiên , mặc cho những mối quan hệ tốt ở Ph...</td>\n",
       "      <td>Tuy nhiên , mặc cho nhg mối Quan hệ tốt ở phố ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Trong dài hạn , Siegel cho biết : Những mối qu...   \n",
       "1  Hiện tại , Harvard đang nỗ lực sắp xếp lại cơ ...   \n",
       "2  Và việc rút vốn khỏi công ty của Mindich là mộ...   \n",
       "3  Giống như nhiều đối thủ khác , Harvard đã từ l...   \n",
       "4  Tuy nhiên , mặc cho những mối quan hệ tốt ở Ph...   \n",
       "\n",
       "                                            generate  \\\n",
       "0  Trong dài hạn , siegel cho biết : Nhữmg mối qu...   \n",
       "1  Hiện tại , harvard đanng nỗ lực sắp p lại cơ c...   \n",
       "2  àV việc Rút vốn khỏi công ty của mindich là mộ...   \n",
       "3  Giống như nhiều đđđối thủ khác , harvard ã từ ...   \n",
       "4  Tuy nhiên , mặc cho nhg mối Quan hệ tốt ở phố ...   \n",
       "\n",
       "                                               label  \n",
       "0  [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, ...  \n",
       "3  [0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, ...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6f9b2af6-def8-44e6-8a91-a515e9e2d776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 & 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5087a251-57e6-429f-a0bb-1ad12fe857a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 4, 4, 4, 9, 16, 36, 64, 121]\n",
      "1 1 1\n",
      "2 4 2\n",
      "3 4 2\n",
      "4 4 2\n"
     ]
    }
   ],
   "source": [
    "a = Solution().maximumLength([4,36,9,16,1,1,4,121,64,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "271edc6e-0f91-42d5-929b-7d71a7ffdc8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 & 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f2833b95-e55a-45cb-96c1-368421b5a3c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7 | 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8387ffc9-77a2-401e-b852-83a3da5b7fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [15,10,1,14,9,4]\n",
    "g = a[0]\n",
    "for i in a[1:]:\n",
    "    g = g | i\n",
    "\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6e2e9022-d92d-48e1-8e74-f82b34dd8774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"0\".isdigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d8af9fbf-bb4d-408b-802a-8b447aeb5c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: 0.9067719578742981\n",
      "True Label: 0.0\n",
      "BCE Loss: 2.372706651687622\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Assuming you have a binary classification problem\n",
    "# Random predictions (logits) and binary labels\n",
    "predictions = torch.randn(1, requires_grad=True)\n",
    "labels = torch.randint(0, 2, (1,), dtype=torch.float32)\n",
    "\n",
    "# Applying sigmoid activation to convert logits to probabilities\n",
    "probabilities = torch.sigmoid(predictions)\n",
    "\n",
    "# Calculating BCELoss\n",
    "criterion = nn.BCELoss()\n",
    "loss = criterion(probabilities, labels)\n",
    "\n",
    "print(\"Predictions:\", probabilities.item())\n",
    "print(\"True Label:\", labels.item())\n",
    "print(\"BCE Loss:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88ff15af-4546-4b1f-a431-4fb569ce081a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 12450, 'passage': 'Vào ngày 1 tháng 9 năm 2013, họ phát hành \"Strong\", đạt vị trí thứ 16 trên UK Singles Chart.\\xa0 Bài hát sau đó đã được sử dụng trong bộ phim truyền hình Mỹ năm 2014 \"Reckless\" cho tập thứ hai của nó, \"Parting Shots\".\\xa0 Vào ngày 9 tháng 9 năm 2013, họ phát hành album phòng thu đầu tay If You Wait, đạt vị trí thứ hai trên Bảng xếp hạng Album của Vương quốc Anh.\\xa0 Nó cũng đạt vị trí thứ hai trên Bảng xếp hạng Album của Úc, vị trí thứ 11 trên Bảng xếp hạng Album của Pháp, vị trí thứ 13 trên Bảng xếp hạng Album của Ireland và vị trí thứ 22 trên Bảng xếp hạng Album của New Zealand.\\xa0 Ban nhạc được ký hợp đồng với Hãng đĩa Columbia tại Hoa Kỳ.Vào ngày 8 tháng 12 năm 2013, một đĩa đơn cho album, \"Nightcall\" được phát hành.\\xa0 Bìa của họ đã được sử dụng một lần nữa cho chương trình \"Reckless\" trong tập cuối \"Civil Wars phần 2\".\\nVào ngày 13 tháng 1 năm 2014, ban nhạc biểu diễn \"Strong\" và \"Wasting My Young Years\" vào Late Night với Jimmy Fallon,đánh dấu màn trình diễn đầu tiên của họ trên truyền hình Mỹ.Vào ngày 1 tháng 4 năm 2014, Official Charts Company thông báo rằng If You Wait của London Grammar là album bán chạy thứ năm của năm 2014 cho đến nay, với doanh số hơn 138.000 bản (tổng số 356.000). London Grammar đã giành được Giải thưởng Ivor Novello ở hạng mục Ca khúc có nhạc và lời hay nhất cho \"Strong\". Và sau đó vào năm 2014, họ đã giành được hai giải thưởng, \"nhạc Indie đột phá của năm\" và \"Giải PPL cho Đạo diễn độc lập mới được stream nhiều nhất\", tại Giải thưởng Âm nhạc Độc lập AIM.\\nVào ngày 2 tháng 9 năm 2014 Nhà thời trang Pháp Dior đã phát hành một chiến dịch quảng cáo cho J\\'Adore có bài hát \"Hey Now\" (Bản phối lại của The Shoes).\\nSau khi Sony Music mua lại Bộ Ghi âm năm 2016, danh mục của London Grammar vẫn được Universal Music Group phân phối ở hầu hết các quốc gia trên thế giới và Because Music ở Pháp.', 'metadata': {'split': 2, 'title': 'London Grammar', 'token_count': 500}, 'responses': {'negative': [{'content': \"Thời trang Pháp Dior đã phát hành chiến dịch quảng cáo cho sản phẩm J'Adore với bản phối lại của bài hát 'Hey Now' của London Grammar.\", 'points': {'me5_large_score': 0.8544074297, 'partial_ratio': 67, 'partial_token_set_ratio': 100, 'partial_token_sort_ratio': 44, 'ratio': 12, 'token_set_ratio': 96, 'token_sort_ratio': 13}}, {'content': \"Ngày mấy Nhà thời trang Pháp Dior phát hành chiến dịch quảng cáo cho J'Adore?\", 'points': {'me5_large_score': 0.8221238852, 'partial_ratio': 88, 'partial_token_set_ratio': 100, 'partial_token_sort_ratio': 50, 'ratio': 8, 'token_set_ratio': 97, 'token_sort_ratio': 8}}, {'content': 'Việc mua lại bộ ghi âm năm 2016 ảnh hưởng đến sự phân phối âm nhạc của london grammar trên toàn cầu như thế nào?', 'points': {'me5_large_score': 0.8375716209, 'partial_ratio': 46, 'partial_token_set_ratio': 100, 'partial_token_sort_ratio': 45, 'ratio': 10, 'token_set_ratio': 81, 'token_sort_ratio': 11}}, {'content': \"Thời trang Pháp Dior sử dụng bài hát 'Hey Now' trong chiến dịch quảng cáo\", 'points': {'me5_large_score': 0.8332011104, 'partial_ratio': 66, 'partial_token_set_ratio': 100, 'partial_token_sort_ratio': 46, 'ratio': 7, 'token_set_ratio': 100, 'token_sort_ratio': 8}}, {'content': 'Một số người hâm mộ nhận xét rằng London Grammar có phong cách âm nhạc độc đáo.', 'points': {'me5_large_score': 0.8071023822, 'partial_ratio': 47, 'partial_token_set_ratio': 100, 'partial_token_sort_ratio': 44, 'ratio': 7, 'token_set_ratio': 70, 'token_sort_ratio': 8}}], 'positive': [{'content': \"Một trong những bài hát của London Grammar, được sử dụng trong phim truyền hình 'Reckless', đạt vị trí cao trên bảng xếp hạng Âu - Mỹ và nhận được giải thưởng Ivor Novello.\", 'points': {'me5_large_score': 0.8629072905, 'partial_ratio': 52, 'partial_token_set_ratio': 100, 'partial_token_sort_ratio': 46, 'ratio': 14, 'token_set_ratio': 94, 'token_sort_ratio': 17}}, {'content': 'Ban nhạc London Grammar đã giành giải thưởng nào tại Giải thưởng Âm nhạc Độc lập AIM năm 2014?', 'points': {'me5_large_score': 0.8530860543, 'partial_ratio': 61, 'partial_token_set_ratio': 100, 'partial_token_sort_ratio': 45, 'ratio': 10, 'token_set_ratio': 98, 'token_sort_ratio': 10}}, {'content': 'London grammar giành được giải thưởng ivor novello năm 2014 và trong lĩnh vực nào họ đoạt giải như thế nào?', 'points': {'me5_large_score': 0.8424084783, 'partial_ratio': 61, 'partial_token_set_ratio': 100, 'partial_token_sort_ratio': 45, 'ratio': 10, 'token_set_ratio': 87, 'token_sort_ratio': 11}}, {'content': \"London Grammar đoạt Giải thưởng Ivor Novello với ca khúc 'Strong'\", 'points': {'me5_large_score': 0.8629845381, 'partial_ratio': 71, 'partial_token_set_ratio': 100, 'partial_token_sort_ratio': 44, 'ratio': 6, 'token_set_ratio': 96, 'token_sort_ratio': 7}}, {'content': 'London Grammar nhận Giải thưởng Ivor Novello cho Ca khúc có nhạc và lời hay nhất với \"Strong\".', 'points': {'me5_large_score': 0.8529629707, 'partial_ratio': 78, 'partial_token_set_ratio': 100, 'partial_token_sort_ratio': 48, 'ratio': 9, 'token_set_ratio': 97, 'token_sort_ratio': 10}}]}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def read_jsonl_file(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Load each line as a JSON object\n",
    "            json_object = json.loads(line.strip())\n",
    "            data.append(json_object)\n",
    "    return data\n",
    "\n",
    "# Replace 'example.jsonl' with the path to your JSONL file\n",
    "file_path = '../synthetic_data_27_01_24.jsonl'\n",
    "result = read_jsonl_file(file_path)\n",
    "\n",
    "# Now 'result' contains a list of dictionaries, each representing a JSON object from the file\n",
    "print(result[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e983757-198a-4e99-9e57-389670468827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cf3a95f-1b08-457a-aaf8-7d3fcbcf2c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12450"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c947b610-23ba-46e8-a2bf-9b4febfdf311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 1.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "a = torch.tensor([0.1,0.5,0.8,0.9])\n",
    "torch.round(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e344eb6-5f7f-4fe1-b37c-0919448d3413",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
