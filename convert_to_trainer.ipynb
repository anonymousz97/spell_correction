{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from docx import Document\n",
    "import random\n",
    "from underthesea import ner, pos_tag\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import copy\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def norm_text(text):\n",
    "\ttext = unicodedata.normalize('NFC', text)\n",
    "\ttext = re.sub(r\"òa\", \"oà\", text)\n",
    "\ttext = re.sub(r\"óa\", \"oá\", text)\n",
    "\ttext = re.sub(r\"ỏa\", \"oả\", text)\n",
    "\ttext = re.sub(r\"õa\", \"oã\", text)\n",
    "\ttext = re.sub(r\"ọa\", \"oạ\", text)\n",
    "\ttext = re.sub(r\"òe\", \"oè\", text)\n",
    "\ttext = re.sub(r\"óe\", \"oé\", text)\n",
    "\ttext = re.sub(r\"ỏe\", \"oẻ\", text)\n",
    "\ttext = re.sub(r\"õe\", \"oẽ\", text)\n",
    "\ttext = re.sub(r\"ọe\", \"oẹ\", text)\n",
    "\ttext = re.sub(r\"ùy\", \"uỳ\", text)\n",
    "\ttext = re.sub(r\"úy\", \"uý\", text)\n",
    "\ttext = re.sub(r\"ủy\", \"uỷ\", text)\n",
    "\ttext = re.sub(r\"ũy\", \"uỹ\", text)\n",
    "\ttext = re.sub(r\"ụy\", \"uỵ\", text)\n",
    "\ttext = re.sub(r\"Ủy\", \"Uỷ\", text)\n",
    "\treturn text\n",
    "\n",
    "\n",
    "with open(\"Viet74K.txt\" , \"r\", encoding='utf-8')  as f:\n",
    "\tvocab = f.readlines()\n",
    "\tvocab = [word.replace(\"\\n\",\"\") for word in vocab]\n",
    "\tvocab = [norm_text(word) for word in vocab]\n",
    "\n",
    "def check(s):\n",
    "\ts2 = norm_text(s)\n",
    "\ttmp = s2.split(' ')\n",
    "\tfor idx, i in enumerate(tmp):\n",
    "\t\tif i not in vocab:\n",
    "\t\t\ttmp[idx] = '<oov>'\n",
    "\tres = ' '.join(x for x in tmp)\n",
    "\treturn s, res\n",
    "\n",
    "\n",
    "BANG_XOA_DAU_FULL = str.maketrans(\n",
    "\t\"ÁÀẢÃẠĂẮẰẲẴẶÂẤẦẨẪẬĐÈÉẺẼẸÊẾỀỂỄỆÍÌỈĨỊÓÒỎÕỌÔỐỒỔỖỘƠỚỜỞỠỢÚÙỦŨỤƯỨỪỬỮỰÝỲỶỸỴáàảãạăắằẳẵặâấầẩẫậđèéẻẽẹêếềểễệíìỉĩịóòỏõọôốồổỗộơớờởỡợúùủũụưứừửữựýỳỷỹỵ\",\n",
    "\t\"A\"*17 + \"D\" + \"E\"*11 + \"I\"*5 + \"O\"*17 + \"U\"*11 + \"Y\"*5 + \"a\"*17 + \"d\" + \"e\"*11 + \"i\"*5 + \"o\"*17 + \"u\"*11 + \"y\"*5,\n",
    "\tchr(774) + chr(770) + chr(795) + chr(769) + chr(768) + chr(777) + chr(771) + chr(803) # 8 kí tự dấu dưới dạng unicode chuẩn D\n",
    ")\n",
    "\n",
    "def xoa_dau_full(txt: str) -> str:\n",
    "\treturn txt.translate(BANG_XOA_DAU_FULL)\n",
    "\n",
    "from_char = \"àáãảạăằắẳẵặâầấẩẫậèéẻẽẹêềếểễệđùúủũụưừứửữựòóỏõọôồốổỗộơờớởỡợìíỉĩịäëïîöüûñçýỳỹỵỷ\"\n",
    "to_char   = \"aaaaaăăăăăăââââââeeeeeêêêêêêđuuuuuưưưưưưoooooôôôôôôơơơơơơiiiiiaeiiouuncyyyyy\"\n",
    "\n",
    "\n",
    "typo = {\"ă\": [\"aw\"], \"â\": [\"aa\"], \"á\": [\"as\"], \"à\": [\"af\"], \"ả\": [\"ar\"],\n",
    "\t\t\"ẫ\": [\"aax\"], \"ấ\": [\"aas\"], \"ầ\": [\"aaf\"], \"ẩ\": [\"aar\"], \"ậ\": [\"aaj\"],\n",
    "\t\t\"ã\": [\"ax\"], \"ạ\": [\"aj\"], \"ắ\": [\"aws\"], \"ổ\": [\"oor\"], \"ỗ\": [\"oox\"],\n",
    "\t\t\"ộ\": [\"ooj\"], \"ơ\": [\"ow\"],\n",
    "\t\t\"ằ\": [\"awf\"], \"ẳ\": [\"awr\"], \"ẵ\": [\"awx\"], \"ặ\": [\"awj\"], \"ó\": [\"os\"],\n",
    "\t\t\"ò\": [\"of\"], \"ỏ\": [\"or\"], \"õ\": [\"ox\"], \"ọ\": [\"oj\"], \"ô\": [\"oo\"],\n",
    "\t\t\"ố\": [\"oos\"], \"ồ\": [\"oof\"],\n",
    "\t\t\"ớ\": [\"ows\"], \"ờ\": [\"owf\"], \"ở\": [\"owr\"], \"ỡ\": [\"owx\"], \"ợ\": [\"owj\"],\n",
    "\t\t\"é\": [\"es\"], \"è\": [\"ef\"], \"ẻ\": [\"er\"], \"ẽ\": [\"ex\"], \"ẹ\": [\"ej\"],\n",
    "\t\t\"ê\": [\"ee\"], \"ế\": [\"ees\"], \"ề\": [\"eef\"],\n",
    "\t\t\"ể\": [\"eer\"], \"ễ\": [\"eex\"], \"ệ\": [\"eej\"], \"ú\": [\"us\"], \"ù\": [\"uf\"],\n",
    "\t\t\"ủ\": [\"ur\"], \"ũ\": [\"ux\"], \"ụ\": [\"uj\"], \"ư\": [\"uw\"], \"ứ\": [\"uws\"],\n",
    "\t\t\"ừ\": [\"uwf\"], \"ử\": [\"uwr\"], \"ữ\": [\"uwx\"],\n",
    "\t\t\"ự\": [\"uwj\"], \"í\": [\"is\"], \"ì\": [\"if\"], \"ỉ\": [\"ir\"], \"ị\": [\"ij\"],\n",
    "\t\t\"ĩ\": [\"ix\"], \"ý\": [\"ys\"], \"ỳ\": [\"yf\"], \"ỷ\": [\"yr\"], \"ỵ\": [\"yj\"], \"ỹ\": [\"yx\"],\n",
    "\t\t\"đ\": [\"dd\"]}\n",
    "\n",
    "teencode_dict = {'mình': ['mk', 'mik', 'mjk','m'], 'vô': ['zô', 'zo', 'vo'], 'vậy': ['zậy', 'z', 'zay', 'za'],\n",
    "\t\t\t\t\t\t'phải': ['fải', 'fai', ], 'biết': ['bit', 'biet'], \"qđxxst\" : [\"qdxxst\"], \"qđst\" : [\"qdst\"], \"đắk\" : [\"đăk\", \"đắc\", \"ddawsk\"],\n",
    "\t\t\t\t\t\t'rồi': ['rùi', 'ròi', 'r'], 'bây': ['bi', 'bay'], 'giờ': ['h'], \"qđ\" : [\"qd\"], \"hđxx\" : [\"hdxx\"], \"qđxx\": [\"qdxx\"], \"csđt\" :[\"csdt\"],\n",
    "\t\t\t\t\t\t'không': ['k', 'ko', 'khong', 'hk', 'hong', 'hông', '0', 'kg', 'kh'], \"lắk\" : [\"lắc\", \"lăk\", \"lawsk\"], \"hđtd\": [\"hdtd\"],\n",
    "\t\t\t\t\t\t'đi': ['di', 'dj'], 'gì': ['j'], 'em': ['e'], 'được': ['dc', 'đc'], \"qsdđ\" : [\"qsdd\"], \"hđ\" :[\"hd\"], \"heroine\" : [\"hêrôin\"], \"qđst\" :[\"qdst\"],\n",
    "\t\t\t\t\t\t'tôi': ['t'], 'chồng': ['ck'], 'vợ': ['vk'], 'facebook' : ['fb'], 'đồng' : ['đ'], \"hngđ\" : [\"hngd\"]\n",
    "\t\t\t\t\t\t}\n",
    "\n",
    "def change_to_teencode(word):\n",
    "\tif word in teencode_dict:\n",
    "\t\treturn random.choice(teencode_dict[word])\n",
    "\telse:\n",
    "\t\treturn word\n",
    "\n",
    "def check_syll_vn(txt):\n",
    "\tif norm_text(txt) in vocabs:\n",
    "\t\treturn True\n",
    "\telse:\n",
    "\t\treturn False\n",
    "# bỏ dấu 1 từ random\n",
    "def random_remove_accent(text_src, text_des, index, thresh_hold=1):\n",
    "\ttexts = split_word_with_bound(text_src)\n",
    "\ti = index\n",
    "\tif (check_syll_vn(texts[i]) and remove_accent(texts[i]) != texts[i]):\n",
    "\t\tprob = random.random()\n",
    "\t\tif prob < thresh_hold:\n",
    "\t\t\ttexts[i] = remove_accent(texts[i])\n",
    "\n",
    "\treturn ' '.join(texts), text_des\n",
    "\n",
    "error = ['capital_error','spell_error','remove_tone','remove_char','add_char','swap_char','typo','duplicate_char']\n",
    "\n",
    "error_addition = [\"name\",\"place\"]\n",
    "\n",
    "\n",
    "lst_change_tone = [\n",
    "\t['a','ă','â','á','à','ả','ã','ạ','ắ','ằ','ẳ','ẵ','ặ','ấ','ầ','ẩ','ẫ','ậ'],\n",
    "\t['d','đ'],\n",
    "\t['e','ê','é','è','ẻ','ẽ','ẹ','ế','ề','ể','ễ','ệ'],\n",
    "\t['i','í','ì','ỉ','ĩ','ị'],\n",
    "\t['u','ư','ú','ù','ủ','ũ','ụ','ứ','ừ','ử','ữ','ự'],\n",
    "\t['o','ô','ơ','ó','ò','ỏ','õ','ọ','ố','ồ','ổ','ỗ','ộ','ớ','ờ','ở','ỡ','ợ'],\n",
    "\t['y','ý','ỳ','ỷ','ỹ','ỵ']\n",
    "]\n",
    "\n",
    "def duplicate_position(s, pos, n):\n",
    "\tif pos < 0 or pos > len(s):\n",
    "\t\treturn s\n",
    "\tif n < 1:\n",
    "\t\treturn s\n",
    "\treturn s[:pos] + s[pos] * n + s[pos+1:]\n",
    "\n",
    "def gen_err(i):\n",
    "\tprint(\"Dan\")\n",
    "\tif len(i) < 2:\n",
    "\t\treturn i\n",
    "\tchoice = random.sample(error,1)[0]\n",
    "\tprint(choice)\n",
    "\tif choice == 'capital_error':\n",
    "\t\tprint(\"input : \",i)\n",
    "\t\tif i[0].isupper():\n",
    "\t\t\tprint(\"output : \",i.lower())\n",
    "\t\t\treturn i.lower()\n",
    "\t\telse:\n",
    "\t\t\tprint(\"output : \",i.capitalize())\n",
    "\t\t\treturn i.capitalize()\n",
    "\telif choice == 'remove_tone':\n",
    "\t\tprint(\"input : \",i)\n",
    "\t\tprint(\"output : \",xoa_dau_full(i))\n",
    "\t\treturn xoa_dau_full(i)\n",
    "\telif choice == 'spell_error':\n",
    "\t\tprint(\"input : \",i)\n",
    "\t\tchange_idx = []\n",
    "\t\tfor idx, j in enumerate(i):\n",
    "\t\t\tfor g in lst_change_tone:\n",
    "\t\t\t\tif j in g:\n",
    "\t\t\t\t\tchange_idx.append(idx)\n",
    "\t\tif len(change_idx) == 0:\n",
    "\t\t\treturn i\n",
    "\t\tc = random.sample(change_idx,1)[0]\n",
    "\t\tfor g in lst_change_tone:\n",
    "\t\t\tif i[c] in g:\n",
    "\t\t\t\tr = [x for x in g if x != i[c]]\n",
    "\t\t\t\tr2 = random.sample(r,1)[0]\n",
    "\t\t\t\ti = i[:c] + r2 + i[c+1:]\n",
    "\t\tprint(\"output : \",i)\n",
    "\t\treturn i\n",
    "\telif choice == 'remove_char':\n",
    "\t\tprint(\"input : \",i)\n",
    "\t\tn_remove = random.sample([1,2],1)[0]\n",
    "\t\tif len(i)-2 < n_remove:\n",
    "\t\t\treturn i\n",
    "\t\telse:\n",
    "\t\t\ttmp = list(i)\n",
    "\t\t\tpos = random.sample([x for x in range(len(tmp))], n_remove)\n",
    "\t\t\ttmp = [x for idx, x in enumerate(tmp) if idx not in pos]\n",
    "\t\t\tres = ''.join(v for v in tmp)\n",
    "\t\t\tprint(\"output : \", res)\n",
    "\t\t\treturn res \n",
    "\telif choice == 'add_char':\n",
    "\t\tkeyboard = \"qwertyuiop\\[\\]';lkjhgfdsazxcvbnm,./QWERTYUIOP\\{\\}\\\":LKJHGFDSAZXCVBNM<>?\"\n",
    "\t\tprint(\"input : \",i)\n",
    "\t\tpos = random.randint(0, len(i)-1)\n",
    "\t\ttmp = list(i)\n",
    "\t\tc = tmp[pos]\n",
    "\t\ttry:\n",
    "\t\t\tk = keyboard.index(c)\n",
    "\t\texcept:\n",
    "\t\t\treturn i\n",
    "\t\tnew_c = random.sample([1,-1],1)[0]\n",
    "\t\ttry:\n",
    "\t\t\tc = keyboard[k+new_c]    \n",
    "\t\texcept:\n",
    "\t\t\treturn i\n",
    "\t\tres = tmp[:pos] + [c] + tmp[pos+1:]\n",
    "\t\tres = ''.join(g for g in res)\n",
    "\t\tprint(\"output : \",res)\n",
    "\t\treturn res\n",
    "\telif choice == 'swap_char':\n",
    "\t\tprint(\"input : \",i)\n",
    "\t\ttmp = list(i)\n",
    "\t\tpos = random.sample([x for x in range(len(tmp))], 2)\n",
    "\t\tv = tmp[pos[0]]\n",
    "\t\ttmp[pos[0]] = tmp[pos[1]]\n",
    "\t\ttmp[pos[1]] = v\n",
    "\t\tres = ''.join(v for v in tmp)\n",
    "\t\tprint(\"output : \", res)\n",
    "\t\treturn res \n",
    "\telif choice == 'typo':\n",
    "\t\tprint(\"input : \",i)\n",
    "\t\ttmp = list(i)\n",
    "\t\tfor idx, j in enumerate(tmp):\n",
    "\t\t\tif j in list(typo.keys()):\n",
    "\t\t\t\tres = tmp[:idx] + typo[j] + tmp[idx+1:]\n",
    "\t\t\t\tres = ''.join(g for g in res)\n",
    "\t\t\t\tprint(\"output : \", res)\n",
    "\t\t\t\treturn res\n",
    "\t\treturn i\n",
    "\n",
    "\telif choice == 'duplicate_char':\n",
    "\t\t#print(\"input : \",i)\n",
    "\t\tpos = random.randint(0,len(i)-1)\n",
    "\t\tr = random.randint(2,3)\n",
    "\t\tres = duplicate_position(i,pos, r)\n",
    "\t\t#print(\"output : \", res)\n",
    "\t\treturn res\n",
    "\n",
    "\treturn \"\"\n",
    "\n",
    "def generate_error(text, rate=0.2, addition_err=True):\n",
    "\ttext = text.strip()\n",
    "\ttmp = copy.deepcopy(text).split(' ')\n",
    "\tlst_pos = [0]\n",
    "\tlabel = [0] * len(tmp)\n",
    "\tfor i in tmp[:-1]:\n",
    "\t\tlst_pos.append(len(i)+lst_pos[-1]+1)\n",
    "\n",
    "\tprint(tmp)\n",
    "\n",
    "\tif addition_err:\n",
    "\t\toutput_err = ner(text, deep=True)\n",
    "\t\tfor i in output_err:\n",
    "\t\t\tif i['start'] in lst_pos:\n",
    "\t\t\t\tif i['word'][0].isupper():\n",
    "\t\t\t\t\ti['word'] = i['word'].lower()\n",
    "\t\t\t\t\tidx = lst_pos.index(i['start'])\n",
    "\t\t\t\t\ttmp[idx] = i['word']\n",
    "\t\t\t\t\tlabel[idx] = 1\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tcontinue\n",
    "\tfor idx, i in enumerate(tmp):\n",
    "\t\trand = random.random()\n",
    "\t\tif rand < rate:\n",
    "\t\t\tr = gen_err(i)\n",
    "\t\t\tprint(\"gen : \",i,r)\n",
    "\t\t\tif r == i:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\ttmp[idx] = r\n",
    "\t\t\tlabel[idx] = 1\n",
    "\t\t\t\n",
    "\t\n",
    "\tres = ' '.join(x for x in tmp)\n",
    "\treturn text, res, label\n",
    "\n",
    "n_gen = 5\n",
    "lst_gt = []\n",
    "lst_gen = []\n",
    "lst_label = []\n",
    "\n",
    "# lst_file = os.listdir('./')\n",
    "# for file in tqdm(lst_file):\n",
    "# \t# #print(file)\n",
    "# \tif not file.endswith('.docx') or '~' in file:\n",
    "# \t\tcontinue\n",
    "# \tdocument = Document(file)\n",
    "# \tfor i in document.paragraphs:\n",
    "# \t\tfor j in range(n_gen):\n",
    "# \t\t\tif len(i.text) < 5:\n",
    "# \t\t\t\tcontinue\n",
    "# \t\t\ttext, tmp, label = generate(i.text)\n",
    "# \t\t\tlst_gt.append(i.text)\n",
    "# \t\t\tlst_gen.append(tmp)\n",
    "# \t\t\tlst_label.append(label)\n",
    "\n",
    "\n",
    "# df = pd.DataFrame({\"text\":lst_gt,'generate':lst_gen,\"label\":lst_label})\n",
    "# #print(df.shape)\n",
    "# df.to_excel('gen_err.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hôm', 'nay', 'thời', 'tiết', 'thật', 'dễ', 'chịu']\n",
      "Dan\n",
      "add_char\n",
      "input :  Hôm\n",
      "output :  Hôn\n",
      "gen :  Hôm Hôn\n",
      "Dan\n",
      "swap_char\n",
      "input :  tiết\n",
      "output :  ttếi\n",
      "gen :  tiết ttếi\n",
      "Dan\n",
      "capital_error\n",
      "input :  chịu\n",
      "output :  Chịu\n",
      "gen :  chịu Chịu\n",
      "Hôm nay thời tiết thật dễ chịu\n",
      "Hôn nay thời ttếi thật dễ Chịu\n",
      "[1, 0, 0, 1, 0, 0, 1]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "a, b, c = generate_error(\"Hôm nay thời tiết thật dễ chịu\", rate=0.2, addition_err=False)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
